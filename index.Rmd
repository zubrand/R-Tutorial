---
title: "R Tutorial"
sibtitle: "Economic Demography I"
author: "Andriy Zhubryd"
date: "June 21,2016"
output: 
  html_document:
    fig_width: 8
    keep_md: yes
    number_sections: yes
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: yes
      smooth_scroll: yes
ext_widgets : {rCharts: ["libraries/highcharts","libraries/nvd3", "libraries/morris", "libraries/leaflet", "libraries/rickshaw"]}
mode: standalone
---

```{r global_options, echo = F}
knitr::opts_chunk$set(fig.align = 'center', cache = T)
library(dplyr, warn.conflicts = F)
library(knitr, warn.conflicts = F)
```

# Start with R
## Introduction

R is one of the most popular languages of statistical programming. It means that it cannot be used for development of end-to-end standalone applications (unlike python) and it's focused on statistical computations. This computational aspect can be seen everywhere: from data types to main functions and variables. After all, R console is designed to receive commands one-by-one, not the code of whole application in the beginning.

## Data types

To understant how R works, we should start with the main data types available:

* Elementary: numeric, character, date, boolean. Those are the basic one-element data types, available with the same qualities in every programming language.

* Vector: vectors of elementary variables. Widely used in R, a lot of functions are vector-oriented, meaning that they process vector as a whole, not an element separately.

* Factor: factor is the special case of vector, implemented in R. It's used for character vectors and idea behind is to extract distinct value from vector (so-called `levels`) store character vactor as vector of integers (number of level of this value) and levels. Factors are very suitable for grouping/regrouping both categorical and numerical variables and for usage in modelling.

* Matrix, array: matrix and n-dimensional arrays are the extensions of vector in multiple dimensions.

* Data Frame: usual table of data, where rows are cases and attributes. Analog of table of relative databases. Probably the main variable in R, used in storing, processing, import & export operations.

* List: collection of other variables. Is suitable for grouping related variables or complex objects (e.g. model). Elements of list can be of different type (e.g. data frame, elementary, vector).

## Simple operations

Now that we know the data types, we can look at the simple operations in R. They will be provided with comments so that you can better understand their function:

1. Elementary variables

```{r simple_elementary}
# Numeric
a <- 5 # or a = 5
a
class(a) # type - numeric

# Character
string <- "You are a good strudent"
string
class(string)

# Boolean
b <- 1 == 2
b
class(b)

# Date
d <- Sys.Date()
d
class(d)
```

2. Vector

```{r simple_vector}
v <- c(1,2,3,4,5)
v
class(v) # class of elements
is.vector(v)

v2 <- c(TRUE, FALSE, 5, 10)
v2 # numeric can fit boolean, but boolean cannot fit numeric like 5. Therefore, it will be saved as numeric - maximum of individual complexities.
class(v2)

v3 <- c(TRUE, 5, "R")
v3
class(v3) # character "R" has the highest complexity

# Subsetting elements from vector
v[1] # first element
v[-2] # whole vector except element #2
v[c(1,3,5)] # elements #1,3,5

# Sorting vector
sort(v2) # sorted vector
order(v2) # which order (ascending) have elements in current sequence
```

3. Factor

```{r simple_factor}
f <- factor(c("M","M","M","F","F","F"))
str(f) # How is stored: levels and numeric vector
levels(f) # levels of factor
as.numeric(f) # numeric vector of factor
f

# Checking data type
class(f)
is.factor(f)
```

4. Matrix, array

```{r simple_matrix}
# Matrix
M <- matrix(1:16, nrow = 4, ncol = 4)
M

# Checking data type
is.vector(M)
is.matrix(M)
is.array(M) # Matrix is subtype of array with 2 dimensions
class(M)

M[1,3] # Extracting exact element

# array
A <- array(1:120, dim = 5:2)
A # 4-dimensional array

class(A)
is.vector(A)
is.matrix(A)
is.array(A)

dim(A) # size of A (instances in each dimension)
length(dim(A)) # number of dimensions

A[2,1,2,1] # Extracting exact element
```

5. Data frame

```{r simple_dataframe}
df <- data.frame(size = c(1,4,7,3), price = c(2,6,4,2), type = factor(c("New", "Old", "New", "New")))
df

str(df) # structure of data.frame

# Check data type
class(df)
is.matrix(df)
is.data.frame(df)

df$type # Extracting column
df$type[2] # Extracting exact element
names(df) # names of columns
```

6. List

```{r simple_list}
l <- list(f = f, df = df, v2 = v2, b = b)
l

str(l)

# Checking data type
class(l)
is.list(l)

names(l) # names of elements

l$f # extracting element of list
l$df$price # column of element of list
l[[1]] # first element of list
```

## Import

As usual, first step of data processing in R is importing the data. Data can be in various forms and locations, but the most basic one is a text file (usually `*.csv`) on the local hard drive:

```{r import}
dt_total <- read.csv("D:/OneDrive/VSE/II/R Tutorial/Data/dt_total.csv")
dt_pyramid <- read.csv("D:/OneDrive/VSE/II/R Tutorial/Data/dt_pyramid.csv", header = T, sep = ",", quote = '"', stringsAsFactors = T)

class(dt_total)
str(dt_total)
head(dt_total, 10)
```

Also, you may face the problem to upload data in some specific format: matlab, fortran, JSON, Excel sheet, ODBC, etc. For these cases exist special libraries, which you can find [here](http://cran.r-project.org/web/packages/available_packages_by_name.html).

## Chain operator

One of very useful operators in R, which I use quite ofter, is element `%>%`. It is called chaining operator and is a part of *dplyr* package. This operator is handing element on the left to the function on the right as the first argument. It helps to make complicated nested formulas easier to comprehend:

```{r chain_example, eval=FALSE}
# Simple example
    filter(dataset, field == "value") 
        # is equal to
    dataset %>% filter(field == "value")

# More complex example
    summarize(group_by(filter(dataset, field == "value"), group_field), function(value_field))
        # is equal to
    dataset %>% filter(field == "value") %>% group_by(group_field) %>% summarize(function(value_field))
```

As you can see from the second example, chaining operator makes your code much more easier to read. That's why it's used throughout the paper.

# Data transformation

After mastering the basics, you should switch to serious step: data transformation and analysis. This section will review main points on how to work with data in R.

## Binding

Binding is the simplest way how to unite few datasets, add a row, etc.:
```{r binding}
rbind(c(1,2,3,4), c(10,9,8,7)) # binding 2 rows
cbind(c(1,2,3,4), c(2,4,1,1)) # binding 2 columns
```

## dplyr

*dplyr* is a special package (one of few), dedicated to data transformation. Operatios, available in dplyr can be compared with SQL: select, group_by, etc.:

```{r dplyr_example}
library(dplyr)

dt_total %>% filter(Geo == "DE_TOT" & Year == 2013) # Filtering
dt_total %>% group_by(Year) %>% summarize(Total_Population = sum(Population, na.rm = T)) %>% head() # Grouping
dt_total %>% mutate(Pop_mln = Population/10^6) %>% head() # Changing columns
```

## Merging

Merging is another analogy from the SQL and it corresponds to JOIN (INNER, LEFT) command:

```{r merge_example}
df
sizes <- data.frame(size = c(1, 4, 7, 10),  description = c("small", "medium", "big", "huge"))
sizes

# Merge df and sizes to add column description to the df
merge(df, sizes, by = "size") # INNER JOIN
merge(df, sizes, by = "size", all = T) # FULL JOIN
merge(df, sizes, by = "size", all.x = T) # LEFT JOIN
merge(df, sizes, by = "size", all.y = T) # RIGHT JOIN
```

Merge is quite important during various transformations of data. For example, to calculate age distribution of population:
```{r merge_age}
tmp_age <- dt_pyramid %>% filter(Year >= 2010 & Geo == "CZ") %>% 
  mutate(Population = F + M) %>% select(Age, Year,Population) %>%
  filter(!is.na(Population))
tmp_age %>% head()

total_population <- tmp_age %>% group_by(Year) %>% summarize(Total = sum(Population, na.rm = T))
total_population %>% head()

merge(tmp_age, total_population, by = "Year") %>% mutate(Share = Population/Total) %>% 
  arrange(Year, Age) %>% head()
```

## Reproducibility

Advantage of R against, for instance, Excel is that user has to describe all hist actions with data in code and this code can be run on the other continent and still has same results in case of same imputs. This is reproducibility.

Reproducibility is very important for scientific data analyses and reseatch papers because it allows your opponent to make sure that your calculations are correct. Otherwise, credibility of your paper/research will fall immediately.

To gain reproducibility, you have to follow few main steps:

1. Do all data transformation in R. In case you do some quick and obvious data cleaning in Excel, it won't be in R code and you R code would yield different results from raw input data. Ideally, you shouldn't even download the file manually, but use direct links to the data sources in your R code.

2. Set seed: this is a randomizator setting. Setting seed will ensure you receive identically same results of random generation during the next run. Let's see it on the example:

```{r reproducibility}
set.seed(1234)
r1 <- rnorm(10)
r2 <- rnorm(10)

set.seed(1235)
r3 <- rnorm(10)

set.seed(1234)
r4 <- rnorm(10)

cbind(r1, r2, r3, r4) # You can easily see that columns #1 and #4 appear similar

# Detailed check
r1 == r4 # this means that columns are the same
r1 == r3 # all pairs of values are different
r1 == r2 # different

all.equal(r1, r4) # another way to check
```

## Functions

Next important step for user in R is to create his/her own functions. Functions are easy and they allow to make your code more efficient and ogranized by coding into functions repeating chunks of code.

One of good examples of function would be to calculate some index. Let's take as an example index of masculinity:

```{r functions_elementary}
Masculinity_elementary <- function(M, F) M/F # Very easy form of function

Masculinity_elementary(100, 103) # Easy
Masculinity_elementary(c(100, 89, 103), c(103, 180, 50)) 
```

As we see, if we apply it on the vectors, it will be calculated on each pair of `M` and `F` separately and output will be vector. Let's build another function that will calculated total index of masculinity for vector input:

```{r functions_vector}
Masculinity_vector <- function(M, F) sum(M)/sum(F)

Masculinity_vector(100, 103) # Still works nice
Masculinity_vector(c(100, 89, 103), c(103, 180, 50)) # Now it works
```

Now it works fine with both vectors and elementary values. What about situation when you have dataframe with 2 columns: Sex and Population. In this case you would have to split it somehow before applying our function. Also, you can use your previously created functions in the new ones:

```{r functions_df}
df <- data.frame(Sex = factor(c("M","M","M","F","F","F")), Population = c(100, 89, 103, 103, 180, 50))
df

Masculinity_dataframe <- function(data) Masculinity_vector(df$Population[df$Sex == "M"], df$Population[df$Sex == "F"])

Masculinity_dataframe(df)
```

## Apply

There is so-called `apply` family of functions in R. Their point is to take some iterable object (e.g. vector, matrix, list, dataframe) and apply some function on each separated element (can be non-elementary element, e.g. vector). There are following functions in the family:

1. sapply: target is vector, applying function for each element of vector

2. lapply: target is list, applying function for each element of vector

3. apply: target is array (matrix, dataframe), applying for each cut (row or column)

4. mapply: targets are vectors, which are the arguments of one function

Let's see them in action:
```{r apply}
# sapply
v
sapply(v, sqrt) # Take square root of each element
sqrt(v) # Luckily, function `sqrt` is adapted for usage on vectors

# lapply
str(l)
lapply(l, class) # type of each object in the list
lapply(l, dim) # dimensions of each element of the list
lapply(l, names) # names of columns of elements of the list

# apply
M

apply(M, MARGIN = 1, mean) # means of custs by 1-st dimensions (average of each row)
rowMeans(M) # same as our `apply` formula

apply(M, MARGIN = 2, mean) # means by 2nd dimension (average of each column)
colMeans(M) # same


# mapply
mapply(FUN = function(x,y) x*y, x = 1:4, y = 2:-1) # mutliplying corresponding elements: 1*2, 2*1, 3*0, 4*(-1)
```


# Data visualization

## Base

After data analysis and transformation comes data visualization to really see what your numbers are. The most elementary graphics is provided in the package `base`, but it's not very flexible and estetic. It's super-easy and intuitive, but it won't satisfy you for long:

```{r base_graphics}
set.seed(20)
x <- rnorm(10)
y <- runif(10)

plot(x, y, main = "Simple plot")

plot(x, y, type = "b", main = "Plot with both lines and point")
abline(h = .5, col = "red")
abline(v = 0, col = "red")
```

R has 2 advanced widely used graphic libraries: `ggplot2` and `lattice`. My personal favourite is `ggplot2`, so we'll look in more detail at it in the following section.

## ggplot2

Library `ggplot2` was created based on book 'Grammar of Graphics' and is supposed to make your chart building like creating a sentence. It's very powerful and flexible, but sometimes not easy to find solution on your own. Luckily, internet is full of documentation, tutorials and examples of ggplot and, from my own experience, you can always find an answer to your question.

So let's start with examples of ggplot's possibilities:

```{r ggplot2}
library(ggplot2)
df <- data.frame(size = sample(1:10, 20, T), price = runif(20, min = 2, max = 15), type = factor(sample(c("New","Old"), 20, T)))
df

ggplot(data = df, mapping = aes(x = size, y = price)) + geom_point() + 
  ggtitle("Simple basic graph")


```

As you can see, simple basic graph looks much better in `ggplot2`. Let's assume we need more details on the graph:

```{r ggplot2_2}
# Adding 'type' on the plot
df %>% ggplot(aes(x = size, y = price, color = type)) + geom_point() # differentiation by type
df %>% ggplot(aes(x = size, y = price)) + geom_point() + facet_wrap(~type)  # differentiation by type | version 2

# Quick fitting of prediction models
df %>% ggplot(aes(x = size, y = price)) + geom_point() +
  stat_smooth(method = "lm") + ggtitle("Linear regression fit with confidence interval")

df %>% ggplot(aes(x = size, y = price)) + geom_point() +
  stat_smooth(method = "loess", se = F) + ggtitle("Loess fit")

df %>% ggplot(aes(x = size, y = price, color = type)) + geom_point() +
  stat_smooth(method = "lm", se = F) + 
ggtitle("Linear regression fit\ndifferentiation by type")
```

You can see how quickly and nicely we can graphically fit different models or create mutliple graphs. Further, let's look what other could be done in ggplot with examples on real demographic data:

```{r ggplot_dem}
# Adding generation columns to the dataset
dt_pyramid <- dt_pyramid %>% 
  mutate(Gen_bio = cut(Age, include.lowest = T, breaks = c(0, 15, 50, 100), right = F),
         Gen_eco = cut(Age, include.lowest = T, breaks = c(0, 20, 65, 100), right = F))


tmp <- dt_pyramid %>% filter(Geo %in% c("CZ", "ES") & between(Year, 2000, 2010)) %>% 
  group_by(Gen_eco, Year, Geo) %>% summarize(Population = sum(F+M))
g <- tmp %>% group_by(Year, Geo) %>% summarize(Tot = sum(Population)) %>% merge(tmp) %>%
         mutate(Share = Population/Tot * 100) %>% arrange(Gen_eco) %>%
         ggplot(aes(x = Year, y = Share, color = Gen_eco, fill = Gen_eco)) + geom_area() +
         facet_wrap(~Geo) + ggtitle("Comparison of countries by economical generations")
g
```

Our example is quite complex because it's, also, calculating distribution of population by economical generations in Czech Republic and Spain for period of 2000-2010. Further examples of `ggplot2` in Economic Demography will the in section 'Demography in R'.

## Interactive charts

Interactive plots are so much nicer and more interesting for us because we can find out more from them. R has few libraries for interactive plotting and the idea behind is that those plots are based on JavaScript and can be used in HTML reports and presentation. Let's have a quick look at each of the plotting libraries:

1. googleVis

```{r googleVis}
library(googleVis)


# Preparation of data: different ratios
library(reshape2) # for some data manipulation
Ratios <- dt_pyramid %>% 
       filter(Geo %in% c("CZ","ES","NO","SE","DE_TOT") & between(Year, 2000, 2010)) %>%
       group_by(Year, Geo) %>% summarize(Masculinity = sum(M)/sum(F))
     
     Ratios <- dt_pyramid %>% mutate(Tot = M + F) %>% group_by(Year, Geo, Gen_bio) %>% 
       summarize(Tot = sum(Tot)) %>% 
       dcast(Year + Geo ~ Gen_bio, value.var = "Tot", fun.aggregate = sum, na.rm = T) %>%
       setNames(c("Year", "Geo", "I", "II", "III")) %>% mutate(Sauvy = III/I) %>%
       select(Year, Geo, Sauvy) %>% merge(Ratios)
     
     Ratios <- dt_pyramid %>% mutate(Tot = M + F) %>% group_by(Year, Geo, Gen_eco) %>% 
       summarize(Tot = sum(Tot)) %>% 
       dcast(Year + Geo ~ Gen_eco, value.var = "Tot", fun.aggregate = sum, na.rm = T) %>%
       setNames(c("Year", "Geo", "I", "II", "III")) %>% 
       mutate(TDR = (I+III)/II, OADR = III/II, JADR = I/II, Seniority = III/I) %>% 
       select(-I,-II,-III) %>% merge(Ratios)

head(Ratios)
```

```{r gvis2, results='asis'}
M <- gvisMotionChart(Ratios, idvar = "Geo", timevar = "Year", options = list(width = 550, height = 450), chartid = "chartid")
print(M, 'chart')
```

2. rCharts

```{r rcharts, results='asis', comment = NA, cache = F}
library(rCharts)
options(
  rcharts.mode = 'iframesrc', 
  rcharts.cdn = TRUE,
  RCHART_WIDTH = 600,
  RCHART_HEIGHT = 400
)

tmp <- dt_pyramid %>% filter(Geo == "CZ") %>% 
  group_by(Gen_eco, Year) %>% summarize(Population = sum(F+M)) %>%
  mutate(Generation = Gen_eco, Date = as.numeric(as.POSIXct(paste0(Year, "-01-01"))))

# r <- Rickshaw$new()
# r$layer(Population ~ Date, group = "Generation", data = tmp, type = "multiBarChart", width = 600)
# r$set(slider = TRUE)


r <- nPlot(Population ~ Year, group = "Generation", data = tmp %>% filter(Year >= 1990), type = 'stackedAreaChart', id = 'nPlot1')
r$set(title = "Development of economical generation in Czech Republic")
#r$setTemplate(afterScript='<style> svg text {font-size: 9px;}</style>')
#r$yAxis(staggerLabels = FALSE)
r

```

# Demography in R
## Pyramid

First need of specific packages for demography comes with plotting the pyramid chart. There is a special package called `pyramid` for that kind of a plot. Here's how it can be applied:

```{r pyramid}
# Special package
library(pyramid)
dt_pyramid %>% filter(Geo == "CZ" & Year == 2000) %>% select(M, F, Age) %>%
  pyramid(Csize = 1, Cstep = 5, AxisFM = 'd', Cgap = .1, Laxis = 0:4*25000,
          main = "Pyramid of Czech population in 2000")


# Usual ggplot
library(scales) # library for numeric formatting
tmp_pyr <- dt_pyramid %>% filter(Geo %in% c("CZ","BE") & Year %in% c(2000, 2010)) %>%
  select(-X, -Gen_bio, -Gen_eco) %>% melt(id = c("Age", "Geo", "Year")) %>%
  mutate(Sex = variable, Population = value)
ggplot(data = tmp_pyr, aes(x = Age, y = Population, fill = Sex)) + 
  geom_bar(data = subset(tmp_pyr, Sex == "F"), stat = "identity") + 
  geom_bar(data = subset(tmp_pyr, Sex == "M"), aes(y=-Population), stat = "identity") + 
  scale_y_continuous(labels = function(x) comma(abs(x))) + 
  coord_flip() + ggtitle("Pyramid graphs of selected years and countries") +
  scale_fill_brewer(palette = "Set1") +
  facet_grid(Geo ~ Year) + theme_bw()

# ggplot with 5-year grouping
tmp_pyr <- dt_pyramid %>% filter(Geo %in% c("CZ","BE") & Year %in% c(2000, 2010)) %>%
  select(-X, -Gen_bio, -Gen_eco) %>% melt(id = c("Age", "Geo", "Year")) %>%
  mutate(Sex = variable, Population = value, Age = Age - Age %% 5) %>% group_by(Age, Geo, Year, Sex) %>% summarize(Population = sum(Population))
ggplot(data = tmp_pyr, aes(x = Age, y = Population, fill = Sex)) + 
  geom_bar(data = subset(tmp_pyr, Sex == "F"), stat = "identity") + 
  geom_bar(data = subset(tmp_pyr, Sex == "M"), aes(y=-Population), stat = "identity") + 
  scale_y_continuous(labels = function(x) comma(abs(x))) + 
  coord_flip() + ggtitle("Pyramid graphs of selected years and countries\n5-year grouping") +
  scale_fill_brewer(palette = "Set1") +
  facet_grid(Geo ~ Year) + theme_bw()
```

As you can see, special package `pyramid` makes it easy and comfortable to build 1 pyramid. On the other hand, `ggplot2` solution is more complex, but at the same time more powerful, providing possibility to easily compare numerous years and/or countries.

## Indeces
## Life tables
## Projections

# Presentation of results

Of course, any good analysis or research should end with some conclusion, supported by numbers. This conclusion and final numbers has to be readable and easy to digest for user. R has available some main methods of presenting the results (presentation slides and report), but it also has few quite unusual ones: ShinyApp, yhat. In this section we will briefly go through all the the mentioned.

## Report

The document you are currently reading is R report, made in the form of `RMarkdown`. This markdown combines pure R code with formatted text, allowing easy presentation of the results in the form of a report. Formatting of the main text is performed the same way as for the usual markdown documents (`*.md`). The main advantages of rmarkdown reports are:

* Reproducibility: during each generation of the report from markdown code, all chunks of R code are executed, therefore, someone can reproduce and verify your research using rmarkdown code. Also, if you change some code in your analysis, your calculations and final results (including graphs) will be immediately recalculated.

* Fast preparation: rmarkdown report is much faster to prepare in case you are using a lot of graphs and numbers, tables. Exporting tables and figures will take a lot of time, which can be saved by using R report.

* Easy to understand: writing R scripts with comments is good, but if you really need to quickly dive into the problem and understand it from A to Z, R scripts will not do it. With report you see the whole flow of your analysis in one place (text, code and graphs).

* Interactive: you can make you report interact with the user and show different results (numbers, tables, charts). Basically, you can integrate shinyapp inside your report. This feature is available only for html reports. 

* Multiple formats: report can be saved in html, doc or pdf format. Moreover, it can utilize formatting of languages such as LaTeX.

* Easy to share: report can be published in the matter of minutes on RPubs or GitHub.

* Customizable: HTML version of report can be easily customized by using existing themes or your own `css`.

## Presentation

R presentation slides are just a specialized type of usual report.It is made in `rmarkdown` as well, which is conventional: your presentation can be just brief of your report in terms of not only content behind, but, also, r code and formatting. 

Presentations are developed in HTML format and, similarly to reports, can have interactive elements: from quizes to interactive charts.

Regarding the main advantages, they are the same as for the report. As in the case of usual (PowerPoint) presentation, you can add effects and animations to the slides.

```{r echo=F}
#Example of R presentation is provided [here](google.com).
```

## ShinyApp

ShinyApp is unusual way of sharing the R results. It is full website (web application), which interacts with the user by taking his inputs, processing them with R code and then providing the results back to the user on the website. The service is provided by RStudio (most popular IDE for R). 

Special example of ShinyApp for Economic Demography is located [here](https://azhubryd.shinyapps.io/Economic_Demography/) and source code is [here](https://github.com/zubrand/R-Tutorial/Shiny/). This plot is processing some population data from Eurostat and returning basic analyses and figures. User can change the list of analyses, countries and time period and receive results for what he/she selected.

## Yhat

Another quite similar thing is called `yhat`, provided on [this website](http://yhathq.com). It allows you to give your code API: your code receives some input data, processes it and returns some output. The point is that you can used it from other products and programming languages without connection to R (you won't need to adapt your code or migrate it to other language). `yhat` receives input data in the JSON format and sends you back output in JSON format.

## Git

`Git` concept is widely used for programmers to keep track of code. This is especially valuable when working in teams. So same applies to researchers, data scientists: they work with code, they work in teams. Therefore, `git` is useful for them as well.

Git is used not only to develop or solve something, but to share results, knowledge. Quite often there are specified tools to better visualize your research immediately on git provider's website. For example, GitHub provides an option of so called github-pages, where you can integrate you html presentation or report. 

[Here](https://github.com/zubrand/R-Tutorial) is an example of specialized git repository for this tutorial. You can see the list of files and forlders, explore and download them, but the files aren't immediately visualized (e.g. html report is opened as a source code). To 'beautify' git, github-pages were applied and on [this link](https://zubrand.github.io/R-Tutorial/) you can explore the `index.html` file from the git repository mentioned above.

Now you know how to prepare and share your results in R.